{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"/content/GPUPy.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "L4oc2NsjRl-b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"/content/GPUPy.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "6RsfCmlRRl10"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def benchmark_matrix_multiplication():\n",
        "    print(\"=== Matrix Multiplication Benchmark (CPU vs GPU) ===\")\n",
        "    print(\"This benchmark demonstrates GPU advantage in highly parallelizable tasks.\\n\")\n",
        "\n",
        "    # Matrix dimensions to test (N x N)\n",
        "    matrix_sizes = [100, 500, 1000, 2000, 4000, 8000]\n",
        "\n",
        "    cpu_times = []\n",
        "    gpu_times = []\n",
        "    speedups = []\n",
        "\n",
        "    # GPU Warm-up\n",
        "    print(\"Warming up GPU...\")\n",
        "    try:\n",
        "        a_gpu_warmup = cp.random.rand(10, 10)\n",
        "        b_gpu_warmup = cp.random.rand(10, 10)\n",
        "        _ = a_gpu_warmup @ b_gpu_warmup # Perform a dummy operation\n",
        "        cp.cuda.Stream.null.synchronize() # Wait for GPU operations to complete\n",
        "        print(\"GPU ready.\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU warm-up failed: {e}. Ensure CuPy is installed and GPU is available.\")\n",
        "        print(\"Skipping GPU benchmarks.\")\n",
        "        run_gpu = False\n",
        "    else:\n",
        "        run_gpu = True\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for n in matrix_sizes:\n",
        "        print(f\"\\nBenchmarking {n}x{n} Matrix Multiplication:\")\n",
        "\n",
        "        # Generate random matrices on CPU\n",
        "        a_cpu = np.random.rand(n, n)\n",
        "        b_cpu = np.random.rand(n, n)\n",
        "\n",
        "        # CPU Benchmark\n",
        "        start_cpu = time.time()\n",
        "        c_cpu = a_cpu @ b_cpu # Matrix multiplication using NumPy\n",
        "        cpu_time = time.time() - start_cpu\n",
        "        cpu_times.append(cpu_time)\n",
        "        print(f\"CPU Time ({n}x{n}): {cpu_time:.4f}s\")\n",
        "\n",
        "        if run_gpu:\n",
        "            # Transfer matrices to GPU\n",
        "            a_gpu = cp.asarray(a_cpu)\n",
        "            b_gpu = cp.asarray(b_cpu)\n",
        "\n",
        "            # GPU Benchmark\n",
        "            start_gpu = time.time()\n",
        "            c_gpu = a_gpu @ b_gpu # Matrix multiplication using CuPy\n",
        "            cp.cuda.Stream.null.synchronize() # Ensure GPU operations are complete\n",
        "            gpu_time = time.time() - start_gpu\n",
        "            gpu_times.append(gpu_time)\n",
        "\n",
        "            speedup = cpu_time / gpu_time\n",
        "            speedups.append(speedup)\n",
        "            print(f\"GPU Time ({n}x{n}): {gpu_time:.4f}s\")\n",
        "            print(f\"Speedup ({n}x{n}): {speedup:.2f}x\")\n",
        "\n",
        "            # Verify results (optional, but good practice)\n",
        "            c_gpu_np = cp.asnumpy(c_gpu)\n",
        "            if not np.allclose(c_cpu, c_gpu_np, rtol=1e-5, atol=1e-8):\n",
        "                print(\"WARNING: CPU and GPU results differ!\")\n",
        "        else:\n",
        "            gpu_times.append(np.nan)\n",
        "            speedups.append(np.nan)\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Plotting Results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.loglog(matrix_sizes, cpu_times, 'o-', label='CPU Time', color='blue')\n",
        "    if run_gpu:\n",
        "        plt.loglog(matrix_sizes, gpu_times, 's-', label='GPU Time', color='orange')\n",
        "\n",
        "    plt.title('Matrix Multiplication Performance (CPU vs GPU)')\n",
        "    plt.xlabel('Matrix Dimension (N)')\n",
        "    plt.ylabel('Execution Time (s)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
        "\n",
        "    # Add speedup annotations for GPU\n",
        "    if run_gpu:\n",
        "        for i, n in enumerate(matrix_sizes):\n",
        "            if not np.isnan(gpu_times[i]):\n",
        "                plt.annotate(f'{speedups[i]:.1f}x',\n",
        "                             (n, gpu_times[i]),\n",
        "                             textcoords=\"offset points\", xytext=(0,10), ha='center',\n",
        "                             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"b\", lw=0.5, alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('matrix_multiplication_benchmark_gpu_advantage.png')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\": # >>> Bu satırı düzelttim! <<<\n",
        "    benchmark_matrix_multiplication()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSXp-3OuUCmz",
        "outputId": "9ed0dd28-8421-4b59-f2c7-8fbddc18cf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Matrix Multiplication Benchmark (CPU vs GPU) ===\n",
            "This benchmark demonstrates GPU advantage in highly parallelizable tasks.\n",
            "\n",
            "Warming up GPU...\n",
            "GPU ready.\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 100x100 Matrix Multiplication:\n",
            "CPU Time (100x100): 0.0002s\n",
            "GPU Time (100x100): 0.0082s\n",
            "Speedup (100x100): 0.03x\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 500x500 Matrix Multiplication:\n",
            "CPU Time (500x500): 0.0057s\n",
            "GPU Time (500x500): 0.0323s\n",
            "Speedup (500x500): 0.18x\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 1000x1000 Matrix Multiplication:\n",
            "CPU Time (1000x1000): 0.0466s\n",
            "GPU Time (1000x1000): 0.0359s\n",
            "Speedup (1000x1000): 1.30x\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 2000x2000 Matrix Multiplication:\n",
            "CPU Time (2000x2000): 0.2810s\n",
            "GPU Time (2000x2000): 0.1699s\n",
            "Speedup (2000x2000): 1.65x\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 4000x4000 Matrix Multiplication:\n",
            "CPU Time (4000x4000): 3.5704s\n",
            "GPU Time (4000x4000): 0.6927s\n",
            "Speedup (4000x4000): 5.15x\n",
            "--------------------------------------------------\n",
            "\n",
            "Benchmarking 8000x8000 Matrix Multiplication:\n"
          ]
        }
      ]
    }
  ]
}